---
layout: essay
type: essay
title: "AI and It's Use Cases In Learning Software Development"
# All dates must be YYYY-MM-DD format!
date: 2023-11-20
published: true
labels:
  - Engineering
  - AI
---

<img src="https://wp.healthdatamanagement.com/wp-content/uploads/2023/05/shutterstock_2253420073-scaled.jpg" width="100%" />

# AI and its Use Cases

AI is everywhere nowadays. Currently, the big talk is with OpenAI’s product ChatGPT. ChatGPT is a large language model developed with massive content from internet forums and literature. The way it works is based on the input given the language model will predict words that would come next in the context of the input. With a lot of data from the internet, this can result in a chat system that is very close to interacting with a real person. 

Some of the big talk regarding large language models has to deal with use cases in education. Once ChatGPT was released to the public, cheating incidents started to increase in all grade levels with ChatGPT. That is not to say that using ChatGPT in education is a bad thing or something that should not be done, but it should be done sparingly and lead to a better learning outcome. While ChatGPT can write a good paper in a matter of minutes, how much did you learn by doing this? The answer is most likely nothing. By offloading the work to ChatGPT you are cheating yourself from learning something new and interesting.

 Does this mean that we should not use these tools at all in education? Not at all, what I am saying is that we should be wise with our use cases and understand the logic that these large language models are suggesting. For example, I could have ChatGPT write me the code for my WODs, but if I don’t understand it and try to implement it in my code base I am more likely to fail since I don’t understand what is going on. If I let it write the whole code base and it works, if someone were to ask me to edit it for a different use case I am more likely not to be able to complete the task given to me.

This leads me to my case on when we should use AI such as large language models in education. I highly believe that if you understand what you are doing, then I see no real reason why you should not use these tools to get the task done faster. If you understand how everything works, by not using these tools you are doing is wasting your time. I also believe that these models can be really useful in asking questions on topics you don’t understand or summarizing documentation you found on the internet, but I would be cautious while doing this. The main reason I would be very cautious while doing this has to deal with the fact that large language models can hallucinate. You probably have seen this happen before when you asked ChatGPT what is 1 + 1 and it returns 4. We all know that 1 + 1 is not 4 but 2, but in certain cases, ChatGPT can make these logical jumps and return wrong information, after all, large language models are guessing what comes next in the sentence from the previous context.

# Personal Experience with AI Throughout the Semester

## Writing Code

At the start of the semester, we were given full reins to use ChatGPT or any AI tool we wanted and use it as we saw fit in our assignments. While we were given this freedom to do as we saw fit, I didn’t use much of any of these tools. So why didn’t I use ChatGPT to complete my WODs, or use it to write this current essay for class? Well, it all comes down to what would I gain by doing so. If I decided to have ChatGPT write my code or do my essays I would not have learned much or be able to reflect on the experience I have had learning these tools. How can I say I learned anything when I just asked ChatGPT or Bard to do it for me? While I can analyze the code they gave me, it feels like I didn’t do much, and in essence, I don’t feel like I truly worked out the problem that was given to me. 

## Final Project

That is not to say I didn’t use ChatGPT throughout the semester, I just didn’t use it for any assignments to help me with writing the code or essays. I did use ChatGPT's new integration feature with DALLE which is an image generator. This was used to help derive and gain inspiration for our final project and is what created our new logo for the final project. This helped me better visualize and come up with ideas of what our project could look like. If I wanted to test out a look and didn’t want to make a mock-up of it real quick I could just ask it to generate me a real quick mockup with my new parameters.

## WODs

As I said previously I didn’t use any of these AI tools throughout any version of WODs from practice to real ones. Most of that has to do with me wanting to gain experience and learn new things, but it also has to deal with convenience and time. With me not using any AI models for WODs I feel like I saved way more time by doing so. It takes time to prompt AI models with the correct prompt to produce an output you are satisfied with. It also takes time for you to explain your problem and hope that the solution to the problem is the first thing that the AI model will generate. While if I just code it myself, I get to test if what I know is correct, debug errors, and learn new things, and if I don’t know what's wrong I can always google the problem and solve my problem faster than I just used an AI model to do it.

## Learning a Concept / Tutorial

So you may be asking yourself if I didn’t use these large language models for anything else besides the final project how did you complete a task you were stuck on? Well, I mostly just started google searching the problem. I truly believe if you become good at searching up your problems, you don’t need ChatGPT. Would it be helpful to ask the chatbot to solve my problems? Yes, but if I don’t learn how to become an effective user of search engines I am holding myself back in another way. My future job may have code bases that are top secret so I can’t just send their whole code base to OpenAIs servers and pray they don’t care. If I learn how to be very effective with search engineering and solving errors then I am putting myself in a better position.

## Essays

I also chose not to use any language model in any of my essays due to losing the ability to be able to reflect on my experience. As software developers try out new technologies and develop new platforms, I truly believe that we should always reflect on the work that we accomplished and see where things could have been better. These essays are just another way to do that. As you try out new technologies you can see what you like about them and what you don’t. This can lead to opinionated software developers. Now you may be saying isn’t being opinionated a bad thing why would you want to be opinionated? I truly believe as you code and experience more newer technologies you should form opinions on them. These opinions can help you develop better coding philosophies and change the way you view the problem. For example at one point in time people believed websites should ship everything to the client and use their system resources for the bulk of a website processing, but nowadays you are starting to see people move away from that model and develop a hybrid system of sorts, with people using server-side rendering and processing on the first request and hydrating that page with new pieces of data instead of rerendering the whole page, or just making the client take in all the resources and render the whole thing. It took people to take a step back reflect on their design choices, test out their designs, form an opinion on better ways to improve the system, and change their philosophy on programming for the web. By doing this with our essays we are practicing a skill that will become very valuable shortly.

## Answer Questions and Asking Questions

Now I did not use any AI models to ask or answer questions. That is mostly to deal with the fact I doubt many of the answers the model would have given me would be correct due to hallucinations. Does that mean that the answer it probably would have given me would be wrong? No, sometimes asking ChatGPT questions can lead to some really good responses, but to see if the responses were correct I would have to know the subject well, so usually in these cases I just knew it was better to look at the documentation and forums with experts in these fields.

## Code Examples and Explaining the Code

Now I also didn’t use any AI models to generate examples or explain some code snippets, but that is mostly because if you look at the libraries documentation we used they all had code examples with comments explaining the use case. If I just looked at the documentation I could look at the exact version of the library I was using and see a good coding example from the creators of the library. If the library was updated I would have received updated examples for the library. Unlike how if I used ChatGPT to create an example it could use an older version of the library which would lead to broken code.

## Documentation & Debugging

Now I didn’t use ChatGPT to document or debug any of my code due to the fact it does not know my code base. ChatGPT has a word count limit and if I wanted it to be able to document my whole code base, and debug my issues it would need context of my whole code base, which is not very possible/easy to do. This could also lead to hallucinations since you are overloading it with a bunch of data. It would be like giving you a rundown of all of modern physics in an hour and then asking you why can’t we solve string theory yet. You would be so confused and not even know where to start on what is the problem. Same thing, by feeding it all this data from different file sources with sometimes different syntax it's hard for these models to figure out what is happening which leads to hallucinations. 

# Impact on Learning and Understanding

Since I went the route of using very few AI tools in this program I feel like I learned a little bit more than I think I would have if I used an AI tool to help me. This experience made it possible for me to further develop skills such as search engine querying and being able to understand documentation/following issues being discussed on forums like Stackoverflow & GitHub issue pages. While ChatGPT probably could have solved my answers faster in these cases I don’t feel like I would have gained much, and I also feel like I would have been cheated out of these experiences which I know I will need if I try to get a job anywhere else.

# Applications Outside of Class

I feel like slowly we will find more use cases for AI models in current solutions. Companies such as Microsoft are starting to implement ChatGPT in their search engines to make it easier for users of their products to find the answers they are looking for. In the Hawaii Annual Code Challenge, you could see many organizations were pushing for more AI implementations in their current systems. UH Manoa had a challenge where they wanted to implement language models to make it easier for people to find technical articles they have written for accessing information. There are many use cases for AI and right now we are just starting to see the transformation occurring.

# Challenges with AI

Even though I didn’t use any AI models besides DALLE throughout the semester I would say what holds me back from using ChatGPT more has to deal with what I learn, and also the accuracy of the information that comes from these models. If I can’t trust the information coming from them I might as well just search for the answer, where I can get experts in the fields to answer some questions. I also feel like since I can’t trust it I am not truly going to learn anything from it, and also any code it gives me while may be correct, feels like I learned nothing. I want to work and feel like I got the answer by thinking the problem out myself instead of being handed the answer. So I feel like if AI is to get better the first main challenge that these models will need to improve on is the accuracy of the data they are returning. Bing Search has done a good job so far in solving this problem by implementing the internet into the prompt so the AI can get some background information on the topic.

# Analysis & Considerations

As I said before I don’t feel like you are truly learning anything by using ChatGPT if you make it do all the work. I also feel like if you do use it use it sparingly. My stance is you should develop skills like how to search up your problems with search engines. Some may argue that it is also a good skill to develop how to search stuff up on a language model. While they may be correct that it does take some skill to develop the response you want from these models, you are not always going to have this tool at every company (since some companies don’t want you to share their whole code base). I also don’t view it as a really good idea to use them for essays since they can litter your essays with wrong information, and you are not giving yourself some time to reflect on your knowledge and learn from the experience. AI does have a place in the education department I just don’t see it having a major one. I see it as a good way to proofread essays and brainstorm new ideas on how to solve problems. After all, education is meant for people to learn something and understand how we as a society got to the point we are at now. If you just offload all that work to some AI, then what is the purpose of you going to school?

Some improvements I believe we should make to make AI more effective in the education system are by implementing a code of conduct on how to use AI, and also making sure if students do use work generated by AI that they can explain how it works and why they choose to use it. If a student can then do that, they fully understand the concept trying to be taught and also develop a good way to analyze code which is also a very important skill to have when you work on other people's code bases. While the AI models may not be there right now to develop accurate information, eventually we will get there and when we do we should have this foundation set.

# Reflection

While AI is slowly changing the world around us, we should leverage new technologies to better help us. I currently don’t think AI is in the position of making education better at the moment due to the inaccuracies of information it produces, but as time goes on we will start to see better-improved versions. If we are going to schools to learn then we better leverage these tools so we learn. We should not use them as a way to do our work for us, but make it easier to format our ideas, proofread our essays, and brainstorm new ideas. If we can effectively use these new tools our education will be better.
